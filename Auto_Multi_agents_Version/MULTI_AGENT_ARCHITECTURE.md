# Multi-Agent LangGraph Architecture

## Overview

This project now implements a **production-grade multi-agent system** using LangGraph to generate BDD test scenarios. The system coordinates 6 specialized AI agents, each responsible for a specific task in the test generation pipeline.

## Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Browser Automation      â”‚
â”‚  (Playwright / DOM dump)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   DOM Analysis Agent          â”‚
â”‚   - Classifies elements       â”‚
â”‚   - Extracts metadata         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Interaction Classifier      â”‚
â”‚   - Separates hover/popup     â”‚
â”‚   - Categorizes interactions  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚               â”‚
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Hover Agentâ”‚   â”‚ Popup Agent   â”‚
â”‚ - Generatesâ”‚   â”‚ - Generates   â”‚
â”‚   hover    â”‚   â”‚   popup       â”‚
â”‚   scenariosâ”‚   â”‚   scenarios   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚              â”‚
       â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Gherkin Agent            â”‚
â”‚   - Formats scenarios      â”‚
â”‚   - Ensures Gherkin syntax â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Validator Agent          â”‚
â”‚   - Quality checks         â”‚
â”‚   - Validates correctness  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
         .feature files
```

## The 6 Specialized Agents

### 1. DOM Analysis Agent (`dom_agent.py`)
**Responsibility:** Analyzes raw interactions and classifies elements

**Inputs:**
- Raw interactions from Playwright
- DOM structure

**Outputs:**
- Classified interactions with metadata
- Element type (hover/popup/click/other)
- Element descriptions

**Key Features:**
- Extracts element information (text, tag, description)
- Classifies interaction types
- Adds type-specific metadata

---

### 2. Interaction Classifier Agent (`classifier_agent.py`)
**Responsibility:** Separates interactions into specialized categories

**Inputs:**
- Classified interactions from DOM Agent

**Outputs:**
- Categorized dictionary:
  - `hover`: List of hover interactions
  - `popup`: List of popup interactions
  - `click`: List of click interactions
  - `other`: Other interactions

**Key Features:**
- Simple, deterministic classification
- Provides statistics logging
- No LLM required (rule-based)

---

### 3. Hover Agent (`hover_agent.py`)
**Responsibility:** Generates natural language test scenarios for hover interactions

**Inputs:**
- List of hover interactions
- Page URL

**Outputs:**
- List of `HoverScenario` objects with:
  - Feature name
  - Scenario name
  - Gherkin steps
  - Confidence score

**Key Features:**
- **Deterministic navigation scenarios** when dropdown links are known
- LLM-powered scenario generation for complex cases
- Fallback templates when LLM fails
- Smart link selection (avoids generic help links)

**Example Output:**
```gherkin
Feature: Validate navigation menu functionality
Scenario: Verify navigation from menu to What is Tivdak
  Given the user is on the "https://www.tivdak.com/patient-stories/" page
  When the user hovers over the navigation menu "About Tivdak"
  And clicks the link "What is Tivdak?" from the dropdown
  Then the page URL should change to "https://www.tivdak.com/about-tivdak/"
```

---

### 4. Popup Agent (`popup_agent.py`)
**Responsibility:** Generates test scenarios for popup/modal interactions

**Inputs:**
- List of popup interactions
- Page URL

**Outputs:**
- List of `PopupScenario` objects

**Key Features:**
- Tests **BOTH** button actions (Cancel + Continue)
- Uses exact button names from popup
- Includes popup title in scenarios
- Fallback templates for complex popups

**Example Output:**
```gherkin
Feature: Validate Learn More popup functionality
Scenario: Verify popup behavior with cancel and continue actions
  Given the user is on "https://www.tivdak.com/patient-stories/" page
  When the user clicks the "Learn More" button
  Then a popup should appear with the title "You are now leaving tivdak.com"
  When the user clicks the "Cancel" button
  Then the popup should close
  And the user should remain on the same page
  When the user clicks the "Learn More" button
  Then a popup should appear with the title "You are now leaving tivdak.com"
  When the user clicks the "Continue" button
  Then the page should navigate to "https://alishasjourney.com/"
```

---

### 5. Gherkin Agent (`gherkin_agent.py`)
**Responsibility:** Formats scenarios into proper Gherkin syntax

**Inputs:**
- Hover scenarios
- Popup scenarios

**Outputs:**
- List of `GherkinScenario` objects with proper formatting

**Key Features:**
- Ensures all steps start with Gherkin keywords (Given/When/Then/And/But)
- Fixes missing keywords
- Standardizes formatting
- Maintains scenario metadata

---

### 6. Validator Agent (`validator_agent.py`)
**Responsibility:** Validates scenario quality and correctness

**Inputs:**
- Gherkin-formatted scenarios

**Outputs:**
- List of validated scenarios (only valid ones pass)

**Validation Checks:**
1. âœ… Minimum 3 steps required
2. âœ… No empty steps
3. âœ… All steps start with Gherkin keywords
4. âœ… Must have Given, When, Then
5. âœ… No generic phrases ("button element", "the ''")
6. âœ… No empty feature/scenario names
7. âœ… No technical selectors (CSS/XPath)

**Example Rejection:**
```python
# âŒ REJECTED - Generic phrases
"When the user clicks the button element"
"Then a popup should appear with the title ''"

# âœ… ACCEPTED - Specific descriptions
"When the user clicks the 'Learn More' button"
"Then a popup should appear with the title 'You are now leaving tivdak.com'"
```

---

## LangGraph Workflow (`workflow.py`)

The workflow orchestrates all agents in a pipeline:

```python
graph.set_entry_point("dom_analysis")
graph.add_edge("dom_analysis", "classify")
graph.add_edge("classify", "hover")
graph.add_edge("hover", "popup")
graph.add_edge("popup", "gherkin")
graph.add_edge("gherkin", "validate")
graph.add_edge("validate", END)
```

**Execution Flow:**
1. DOM Analysis â†’ Classify interactions
2. Classify â†’ Separate hover/popup
3. Hover Agent â†’ Generate hover scenarios (parallel with Popup)
4. Popup Agent â†’ Generate popup scenarios
5. Gherkin Agent â†’ Format all scenarios
6. Validator Agent â†’ Quality check
7. Return validated scenarios

---

## Configuration

### Enable/Disable Multi-Agent Mode

In `config.py`:

```python
# Multi-Agent Settings
USE_MULTI_AGENT: bool = True  # Set to False for legacy single-agent
```

### Switch Between Modes

**Multi-Agent Mode (Recommended):**
```python
config.USE_MULTI_AGENT = True
```

**Single-Agent Mode (Legacy):**
```python
config.USE_MULTI_AGENT = False
```

---

## Benefits of Multi-Agent Architecture

### Before (Single Agent)
âŒ One giant prompt  
âŒ Inconsistent Gherkin output  
âŒ No modular debugging  
âŒ Hard to extend  
âŒ No specialization  

### After (Multi-Agent LangGraph)
âœ… Agents specialize â†’ output improves  
âœ… Clear separation of responsibilities  
âœ… Easy to replace 1 module (e.g., swap PopupAgent)  
âœ… Parallelization possible  
âœ… Production-grade pipeline  
âœ… Better quality control  
âœ… Easier debugging (see which agent failed)  

---

## Usage

### Basic Usage

```bash
# Uses multi-agent by default
python main.py https://www.tivdak.com/patient-stories/
```

### Force Single-Agent Mode

```bash
# Edit config.py first, then run
python main.py https://www.nike.com
```

### View Agent Logs

```bash
# Enable verbose logging to see each agent's work
python main.py https://www.apple.com --verbose
```

**Expected Log Output:**
```
ğŸ”¬ [Workflow] DOM Analysis Agent...
[DOM_Analysis_Agent] Analyzing 15 interactions...
[DOM_Analysis_Agent] Classified 15 interactions

ğŸ“Š [Workflow] Classifier Agent...
[Interaction_Classifier_Agent] Classification results:
  - Hover: 8
  - Popup: 3

ğŸ–±ï¸  [Workflow] Hover Agent...
[Hover_Agent] Generating scenarios for 8 hover interactions...
[Hover_Agent] âœ“ Generated: Verify navigation from menu to What is Tivdak
[Hover_Agent] Generated 8 hover scenarios

ğŸªŸ [Workflow] Popup Agent...
[Popup_Agent] Generating scenarios for 3 popup interactions...
[Popup_Agent] âœ“ Generated: Verify popup behavior with cancel and continue actions
[Popup_Agent] Generated 3 popup scenarios

ğŸ“ [Workflow] Gherkin Agent...
[Gherkin_Agent] Formatted 11 scenarios

âœ… [Workflow] Validator Agent...
[Validator_Agent] Validating 11 scenarios...
[Validator_Agent] âœ“ Valid: Verify navigation from menu to What is Tivdak
[Validator_Agent] 10/11 scenarios passed validation

âœ… Workflow complete: 10 validated scenarios
```

---

## File Structure

```
BDD_Tests/
â”œâ”€â”€ src/
â”‚   â””â”€â”€ ai/
â”‚       â”œâ”€â”€ agents/
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ dom_agent.py           # Agent 1
â”‚       â”‚   â”œâ”€â”€ classifier_agent.py    # Agent 2
â”‚       â”‚   â”œâ”€â”€ hover_agent.py         # Agent 3
â”‚       â”‚   â”œâ”€â”€ popup_agent.py         # Agent 4
â”‚       â”‚   â”œâ”€â”€ gherkin_agent.py       # Agent 5
â”‚       â”‚   â””â”€â”€ validator_agent.py     # Agent 6
â”‚       â”œâ”€â”€ graph/
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â””â”€â”€ workflow.py            # LangGraph pipeline
â”‚       â”œâ”€â”€ multi_agent_orchestrator.py # New orchestrator
â”‚       â”œâ”€â”€ agent_orchestrator.py      # Legacy single-agent
â”‚       â””â”€â”€ llm_client.py
â”œâ”€â”€ main.py
â”œâ”€â”€ config.py
â””â”€â”€ MULTI_AGENT_ARCHITECTURE.md (this file)
```

---

## Extending the System

### Add a New Agent

1. Create new agent file in `src/ai/agents/`:

```python
# src/ai/agents/my_new_agent.py
class MyNewAgent:
    def __init__(self, llm_client):
        self.llm = llm_client
        self.agent_name = "My_New_Agent"
    
    async def process(self, data):
        # Your logic here
        pass
```

2. Add node to workflow in `workflow.py`:

```python
self.my_agent = MyNewAgent(self.llm)
graph.add_node("my_agent", self._my_agent_node)
graph.add_edge("previous_node", "my_agent")
```

3. Update state in `WorkflowState`:

```python
class WorkflowState(TypedDict):
    # ... existing fields
    my_agent_output: List
```

---

## Troubleshooting

### Issue: "Module 'langgraph' not found"

**Solution:**
```bash
pip install langgraph==0.0.20
```

### Issue: Agents not running

**Check:**
1. Ollama is running: `ollama serve`
2. Model is pulled: `ollama pull llama3.2`
3. Config has `USE_MULTI_AGENT = True`

### Issue: Low quality scenarios

**Solution:**
- Validator Agent will reject them
- Check logs to see which agent failed
- Adjust prompts in specific agent files

---

## Performance

**Single-Agent Mode:**
- ~30-60 seconds for 10 scenarios
- One LLM call per scenario

**Multi-Agent Mode:**
- ~45-90 seconds for 10 scenarios
- Multiple specialized LLM calls
- Better quality output
- More consistent formatting

---

## Future Enhancements

Potential additions to the multi-agent system:

1. **Accessibility Agent** - Add ARIA/accessibility checks
2. **Mobile Agent** - Generate mobile-specific scenarios
3. **Scenario Outline Agent** - Create parameterized scenarios
4. **Background Agent** - Generate common background steps
5. **Parallel Execution** - Run Hover + Popup agents in parallel
6. **Caching Agent** - Cache agent outputs for faster reruns

---

## Conclusion

The multi-agent LangGraph architecture provides a **production-grade, modular, and extensible** system for BDD test generation. Each agent specializes in one task, making the system easier to debug, maintain, and extend.

**Recommended:** Always use `USE_MULTI_AGENT = True` for best results.
